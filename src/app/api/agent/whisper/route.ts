import { NextRequest } from 'next/server';
import OpenAI from 'openai';

// –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI –∫–ª–∏–µ–Ω—Ç–∞
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

// –û—Ç–≤–µ—Ç –æ—Ç API
interface TranscriptionResponse {
  text: string;
  language?: string;
  duration?: number;
}

export async function POST(request: NextRequest) {
  const startTime = Date.now();
  
  try {
    // –ü–æ–ª—É—á–∞–µ–º FormData —Å –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–º
    const formData = await request.formData();
    const audioFile = formData.get('audio') as File;
    const language = (formData.get('language') as string) || '';

    if (!audioFile) {
      return Response.json(
        { error: 'Audio file is required' },
        { status: 400 }
      );
    }

    // –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞ —Ñ–∞–π–ª–∞
    const minSize = 1024; // 1 KB –º–∏–Ω–∏–º—É–º
    const maxSize = 25 * 1024 * 1024; // 25 MB –º–∞–∫—Å–∏–º—É–º
    
    if (audioFile.size < minSize) {
      console.warn(`‚ö†Ô∏è Audio too small: ${(audioFile.size / 1024).toFixed(2)} KB`);
      return Response.json(
        { error: 'Recording too short. Speak longer (min 1 second).' },
        { status: 400 }
      );
    }
    
    if (audioFile.size > maxSize) {
      return Response.json(
        { error: 'Audio file too large (max 25 MB)' },
        { status: 400 }
      );
    }

    console.log(`üé§ Transcribing: ${audioFile.name}, ${(audioFile.size / 1024).toFixed(2)} KB, ` +
      `mime=${audioFile.type || 'unknown'}, langHint=${language || 'auto'}`);

    // –í—ã–∑—ã–≤–∞–µ–º Whisper API
    // Allow Whisper to auto-detect language by omitting the language hint if not explicitly set
    const transcription = await openai.audio.transcriptions.create({
      file: audioFile,
      model: 'whisper-1',
      // language: language || undefined, // omit to auto-detect
      translate: false, // do not force translation to English
      response_format: 'verbose_json',
    });

    const duration = Date.now() - startTime;

    console.log(`‚úÖ Transcribed in ${duration}ms: langDetected=${transcription.language || 'unknown'} -> ` +
      `${transcription.text.substring(0, 100)}`);

    // –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    const response: TranscriptionResponse = {
      text: transcription.text,
      language: transcription.language,
      duration,
    };

    return Response.json(response, { 
      status: 200,
      headers: {
        'X-Response-Time': `${duration}ms`,
      }
    });

  } catch (error) {
    const duration = Date.now() - startTime;
    console.error(`‚ùå Whisper error after ${duration}ms:`, error);

    // –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ OpenAI
    if (error instanceof OpenAI.APIError) {
      const errorMessage = error.message.includes('API key')
        ? 'OpenAI API key not configured. Contact support.'
        : error.message.includes('quota')
        ? 'API quota exceeded. Try again later.'
        : 'Transcription service error. Try again.';
      
      console.error('OpenAI API Error:', {
        status: error.status,
        message: error.message,
        type: error.type,
      });
      
      return Response.json(
        { 
          error: errorMessage,
          text: '',
        },
        { status: 500 }
      );
    }

    // –û–±—â–∞—è –æ—à–∏–±–∫–∞
    return Response.json(
      { 
        error: 'Failed to recognize speech. Try again.',
        text: '',
      },
      { status: 500 }
    );
  }
}

// GET endpoint –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞
export async function GET() {
  return Response.json({
    status: 'ok',
    service: 'OG Lab Agent - Whisper (Optimized)',
    model: 'whisper-1',
    maxFileSize: '25 MB',
    supportedFormats: ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm'],
  });
}
