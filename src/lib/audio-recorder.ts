/**
 * Audio Recording Utility
 * Handles browser audio recording with MediaRecorder API
 */

export type RecordingState = 'idle' | 'recording' | 'processing';

// –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∑–∞–ø–∏—Å–∏ (30 —Å–µ–∫—É–Ω–¥)
export const MAX_RECORDING_DURATION_MS = 30 * 1000;
export const MAX_RECORDING_DURATION_SEC = 30;

export class AudioRecorder {
  private mediaRecorder: MediaRecorder | null = null;
  private audioChunks: Blob[] = [];
  private stream: MediaStream | null = null;
  private maxDurationTimer: NodeJS.Timeout | null = null;
  private onMaxDurationReached?: () => void;
  private keepStreamAlive: boolean = true; // –°–æ—Ö—Ä–∞–Ω—è–µ–º stream –º–µ–∂–¥—É –∑–∞–ø–∏—Å—è–º–∏
  private audioContext: AudioContext | null = null;

  /**
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ª–∏ –±—Ä–∞—É–∑–µ—Ä –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
   */
  static isSupported(): boolean {
    return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
   */
  static async checkMicrophonePermission(): Promise<'granted' | 'denied' | 'prompt'> {
    if (!navigator.permissions || !navigator.permissions.query) {
      // Permissions API –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è (Safari iOS)
      return 'prompt';
    }

    try {
      const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
      return result.state;
    } catch (error) {
      console.warn('Unable to check microphone permission:', error);
      return 'prompt';
    }
  }

  /**
   * –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç callback –¥–ª—è —Å–æ–±—ã—Ç–∏—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
   */
  setOnMaxDurationReached(callback: () => void): void {
    this.onMaxDurationReached = callback;
  }

  /**
   * –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –Ω–∞—á–∏–Ω–∞–µ—Ç –∑–∞–ø–∏—Å—å
   */
  async startRecording(): Promise<void> {
    if (!AudioRecorder.isSupported()) {
      throw new Error('–ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –≤ —ç—Ç–æ–º –±—Ä–∞—É–∑–µ—Ä–µ');
    }

    try {
      // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –∞–∫—Ç–∏–≤–Ω—ã–π stream (–ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞)
      if (!this.stream || !this.stream.active) {
        console.log('üé§ Requesting microphone access...');
        
        // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
        this.stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
          } 
        });
        
        console.log('‚úÖ Microphone access granted');
      } else {
        console.log('üì¶ Reusing existing microphone stream');
      }

      // –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π MIME-—Ç–∏–ø
      const mimeType = this.getSupportedMimeType();
      
      // –°–æ–∑–¥–∞—ë–º MediaRecorder
      this.mediaRecorder = new MediaRecorder(this.stream, {
        mimeType,
        audioBitsPerSecond: 128000, // 128 kbps –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∑–∞–ø–∏—Å–∏
      });

      this.audioChunks = [];

      // –°–æ–±–∏—Ä–∞–µ–º –∞—É–¥–∏–æ-—á–∞–Ω–∫–∏
      this.mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          this.audioChunks.push(event.data);
          console.log(`üì¶ Audio chunk received: ${event.data.size} bytes`);
        }
      };

      // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å —Å —Ç–∞–π–º—Å–ª–∞–π—Å–æ–º 100ms –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö
      this.mediaRecorder.start(100);
      console.log('üé§ Recording started with 100ms timeslice');

      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (30 —Å–µ–∫—É–Ω–¥)
      this.maxDurationTimer = setTimeout(() => {
        console.warn('‚è±Ô∏è Maximum recording duration reached (30s), auto-stopping...');
        if (this.onMaxDurationReached) {
          this.onMaxDurationReached();
        }
      }, MAX_RECORDING_DURATION_MS);

    } catch (error) {
      console.error('Error starting recording:', error);
      const errorMessage = error instanceof Error && error.name === 'NotAllowedError'
        ? '–î–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É –∑–∞–ø—Ä–µ—â—ë–Ω. –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –±—Ä–∞—É–∑–µ—Ä–∞.'
        : '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.';
      throw new Error(errorMessage);
    }
  }

  /**
   * –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø–∏—Å—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞—É–¥–∏–æ blob
   */
  async stopRecording(): Promise<Blob> {
    if (!this.mediaRecorder) {
      throw new Error('No active recording');
    }

    return new Promise((resolve, reject) => {
      if (!this.mediaRecorder) {
        reject(new Error('No active recording'));
        return;
      }

      this.mediaRecorder.onstop = () => {
        const mimeType = this.mediaRecorder?.mimeType || 'audio/webm';
        const audioBlob = new Blob(this.audioChunks, { type: mimeType });
        
        const sizeKB = audioBlob.size / 1024;
        console.log(`üé§ Recording stopped: ${sizeKB.toFixed(2)} KB`);
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ (–º–µ–Ω—å—à–µ 1 KB = —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è –∑–∞–ø–∏—Å—å)
        if (audioBlob.size < 1024) {
          console.warn('‚ö†Ô∏è Recording too short:', sizeKB.toFixed(2), 'KB');
          this.cleanup();
          reject(new Error('–ó–∞–ø–∏—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è. –ì–æ–≤–æ—Ä–∏—Ç–µ –¥–æ–ª—å—à–µ (–º–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥–∞).'));
          return;
        }
        
        // –û—á–∏—â–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã
        this.cleanup();
        
        resolve(audioBlob);
      };

      this.mediaRecorder.stop();
    });
  }

  /**
   * –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π MIME-—Ç–∏–ø –¥–ª—è –∑–∞–ø–∏—Å–∏
   */
  private getSupportedMimeType(): string {
    const types = [
      'audio/webm;codecs=opus',
      'audio/webm',
      'audio/ogg;codecs=opus',
      'audio/mp4',
    ];

    for (const type of types) {
      if (MediaRecorder.isTypeSupported(type)) {
        return type;
      }
    }

    return 'audio/webm'; // fallback
  }

  /**
   * –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Blob –≤ WAV 16kHz mono
   */
  private async ensureAudioContext(): Promise<AudioContext> {
    if (!this.audioContext) {
      const SampleRate = 16000;
      // Safari –∏—Å–ø–æ–ª—å–∑—É–µ—Ç webkitAudioContext
      const Ctx: typeof AudioContext = (window as any).AudioContext || (window as any).webkitAudioContext;
      this.audioContext = new Ctx({ sampleRate: SampleRate });
    }
    return this.audioContext;
  }

  /**
   * –û—á–∏—â–∞–µ—Ç —Ä–µ—Å—É—Ä—Å—ã
   */
  private cleanup(): void {
    // –û—á–∏—â–∞–µ–º —Ç–∞–π–º–µ—Ä –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if (this.maxDurationTimer) {
      clearTimeout(this.maxDurationTimer);
      this.maxDurationTimer = null;
    }
    
    // –ó–∞–∫—Ä—ã–≤–∞–µ–º stream —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ keepStreamAlive = false
    // –ò–Ω–∞—á–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º stream –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–π –∑–∞–ø–∏—Å–∏ (–∏–∑–±–µ–≥–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è)
    if (!this.keepStreamAlive && this.stream) {
      console.log('üîá Closing microphone stream');
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
    
    this.mediaRecorder = null;
  }

  /**
   * –ü–æ–ª–Ω–æ—Å—Ç—å—é –æ—Å–≤–æ–±–æ–∂–¥–∞–µ—Ç –≤—Å–µ —Ä–µ—Å—É—Ä—Å—ã –≤–∫–ª—é—á–∞—è stream
   * –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
   */
  destroy(): void {
    if (this.maxDurationTimer) {
      clearTimeout(this.maxDurationTimer);
      this.maxDurationTimer = null;
    }
    
    if (this.stream) {
      console.log('üîá Destroying microphone stream');
      this.stream.getTracks().forEach(track => track.stop());
      this.stream = null;
    }
    
    this.mediaRecorder = null;

    if (this.audioContext) {
      try { this.audioContext.close(); } catch {}
      this.audioContext = null;
    }
  }

  /**
   * –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –∏–¥—ë—Ç –ª–∏ –∑–∞–ø–∏—Å—å
   */
  isRecording(): boolean {
    return this.mediaRecorder?.state === 'recording';
  }
}

/**
 * –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
 * Whisper —Ç–µ–ø–µ—Ä—å –∞–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —è–∑—ã–∫, –ø–æ–¥—Å–∫–∞–∑–∫–∞ —è–∑—ã–∫–∞ –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è.
 * @param audioBlob - –∞—É–¥–∏–æ blob
 */
export async function transcribeAudio(audioBlob: Blob): Promise<string> {
  // –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–∑–º–µ—Ä–∞
  if (audioBlob.size === 0) {
    throw new Error('–ó–∞–ø–∏—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å –¥–æ–ª—å—à–µ.');
  }
  
  // –ú–∏–Ω–∏–º—É–º 1 KB (–ø—Ä–∏–º–µ—Ä–Ω–æ 1 —Å–µ–∫—É–Ω–¥–∞ —Ä–µ—á–∏)
  if (audioBlob.size < 1024) {
    throw new Error('–ó–∞–ø–∏—Å—å —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∞—è. –ì–æ–≤–æ—Ä–∏—Ç–µ –º–∏–Ω–∏–º—É–º 1 —Å–µ–∫—É–Ω–¥—É.');
  }
  
  if (audioBlob.size > 25 * 1024 * 1024) {
    throw new Error('–ó–∞–ø–∏—Å—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è (–º–∞–∫—Å 25 –ú–ë).');
  }
  
  console.log(`üé§ Source audio: ${(audioBlob.size / 1024).toFixed(2)} KB, type=${audioBlob.type || 'unknown'}`);

  // –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ WAV 16kHz mono –¥–ª—è –ª—É—á—à–µ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
  let uploadBlob: Blob = audioBlob;
  try {
    uploadBlob = await convertToWav16kMono(audioBlob);
    console.log(
      `üéß Converted to WAV16k mono: ${(uploadBlob.size / 1024).toFixed(2)} KB, type=${uploadBlob.type}`
    );
  } catch (e) {
    console.warn('‚ö†Ô∏è WAV conversion failed, sending original blob:', e);
  }

  const formData = new FormData();
  const extension = uploadBlob.type.includes('wav') ? 'wav'
    : uploadBlob.type.includes('webm') ? 'webm'
    : uploadBlob.type.includes('mp4') ? 'mp4'
    : uploadBlob.type.includes('ogg') ? 'ogg'
    : 'wav';
  formData.append('audio', uploadBlob, `recording.${extension}`);

  console.log(`üì§ Sending audio for transcription: ${(uploadBlob.size / 1024).toFixed(2)} KB, ext=.${extension}`);

  const response = await fetch('/api/agent/whisper', {
    method: 'POST',
    body: formData,
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(error.error || '–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å');
  }

  const data = await response.json();
  
  if (!data.text || data.text.trim().length === 0) {
    throw new Error('–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å —á—ë—Ç—á–µ.');
  }
  
  console.log(`‚úÖ Transcription received: "${data.text.substring(0, 50)}..."`);
  
  return data.text;
}

// -------- Helpers: WAV encoding --------
async function convertToWav16kMono(input: Blob): Promise<Blob> {
  // Decode using an AudioContext, resample to 16k mono, and encode WAV
  const arrayBuffer = await input.arrayBuffer();
  const OfflineCtx = (window as any).OfflineAudioContext || (window as any).webkitOfflineAudioContext;

  // First decode at native sample rate
  const tmpCtx = new (window as any).AudioContext();
  const decoded = await tmpCtx.decodeAudioData(arrayBuffer.slice(0));
  try { tmpCtx.close(); } catch {}

  // Prepare resampling to 16k mono
  const targetSampleRate = 16000;
  const numChannels = 1;
  const lengthSeconds = decoded.duration;
  const frameCount = Math.ceil(lengthSeconds * targetSampleRate);
  const offlineCtx = new OfflineCtx(targetSampleRate, frameCount, targetSampleRate);

  // Downmix to mono
  const source = offlineCtx.createBufferSource();
  const monoBuffer = offlineCtx.createBuffer(numChannels, decoded.length, decoded.sampleRate);
  // Mix all channels into channel 0
  const tmp = new Float32Array(decoded.length);
  for (let ch = 0; ch < decoded.numberOfChannels; ch++) {
    const data = decoded.getChannelData(ch);
    for (let i = 0; i < data.length; i++) {
      tmp[i] += data[i] / decoded.numberOfChannels;
    }
  }
  monoBuffer.copyToChannel(tmp, 0, 0);
  source.buffer = monoBuffer;

  const dest = offlineCtx.createDestination();
  source.connect(dest);
  source.start(0);
  const rendered = await offlineCtx.startRendering();

  // Get mono data
  const mono = rendered.getChannelData(0);
  const wavBuffer = encodeWav(mono, targetSampleRate);
  return new Blob([wavBuffer], { type: 'audio/wav' });
}

function encodeWav(samples: Float32Array, sampleRate: number): ArrayBuffer {
  const bytesPerSample = 2; // 16-bit PCM
  const blockAlign = 1 * bytesPerSample;
  const byteRate = sampleRate * blockAlign;
  const dataSize = samples.length * bytesPerSample;
  const buffer = new ArrayBuffer(44 + dataSize);
  const view = new DataView(buffer);

  // RIFF header
  writeString(view, 0, 'RIFF');
  view.setUint32(4, 36 + dataSize, true);
  writeString(view, 8, 'WAVE');

  // fmt chunk
  writeString(view, 12, 'fmt ');
  view.setUint32(16, 16, true); // PCM
  view.setUint16(20, 1, true); // PCM format
  view.setUint16(22, 1, true); // mono
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, byteRate, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, 16, true); // bits per sample

  // data chunk
  writeString(view, 36, 'data');
  view.setUint32(40, dataSize, true);

  // PCM samples
  floatTo16BitPCM(view, 44, samples);
  return buffer;
}

function writeString(view: DataView, offset: number, str: string) {
  for (let i = 0; i < str.length; i++) {
    view.setUint8(offset + i, str.charCodeAt(i));
  }
}

function floatTo16BitPCM(view: DataView, offset: number, input: Float32Array) {
  for (let i = 0; i < input.length; i++, offset += 2) {
    let s = Math.max(-1, Math.min(1, input[i]));
    s = s < 0 ? s * 0x8000 : s * 0x7fff;
    view.setInt16(offset, s, true);
  }
}
